{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kubernetes - Software Development Lifecycle","text":"<p>This project serves as a proof of concept implementation and associated documentation around utilising kubernetes to enable a modern software development lifecycle - not just for software development but platform engineering.</p> <p>Moreover this is living documentation - with the intention to update it with additional caveats and process improvements as the flow hits real world problems.</p> <p>Topics:</p> <ul> <li>High level concepts about the components and moving parts in play.</li> <li>Composition over inheritance in context with infrastructure.</li> <li>External cloud resources and where they fit into the kubernetes ecosystem.</li> <li>End to End change promotion scenarios.</li> <li>A working example using local kubernetes environments.</li> </ul> <p>At a high level this is the resulting output and details of the steps to get there, the rationale for the effort incurred to deliver this design and the business outcomes will be found dispersed throughout the documentation.</p> <p></p>"},{"location":"end-to-end/","title":"End to End - From Requirements to Delivery","text":"<p>This page serves as a step by step guide on taking requirements and following a change control system to complete a change request.</p>"},{"location":"end-to-end/#requirements","title":"Requirements","text":"<p>Let us imagine a ticket to a platform team where an application team to change the state of the clusters via their platform deployment.</p> <p>Framing it as a user story helps frame the use case and deliverable.</p> <p>As a application developer</p> <p>I want utilise the <code>KEDA</code> service to provide <code>ScaledObject</code> functionality on deployments</p> <p>So that I can deploy a horizontally scaled service</p> <p>Note</p> <p>It is worth noting that this ticket is asking for a new service, rather than an upgrade to an existing service. </p> <p>Adding services is the easiest change, removing them the next easiest and upgrading them is the hardest. This is because adding a service has no current users and a hard deprecation of a service is final - ideally with a lot of forewarning for platform users to have removed the dependency in their applications.</p> <p>Upgrading is the most difficult because applications have to be thoroughly tested against a new version of the service. Maintaining a production service through an upgrade cycle is always the most challenging part of the software development lifecycle.</p>"},{"location":"end-to-end/#planning","title":"Planning","text":"<p>The first step to a platform change is to establish if the functionality requested can be achieved in the existing component stack. In this specific example <code>KEDA</code> is a wrapper around a built in kubernetes component (HPA) so the first step would be to check if this functionality can service the needs of the application team. The best component to deploy is none at all.</p> <p>In this fictional scenario the application team has confirmed they need one of the custom scaler policies provided by <code>KEDA</code> and the HPA only being able to scale on basic resource utilisation statistics is not sufficient.</p> <p>The next step is to scope out if the current kubernetes deployments can support the requested service. The documentation found at https://keda.sh/docs/2.0/deploy/ states the only requirement is a kubernetes cluster version 1.16 or greater.</p> <p>In this theoretical example the prerequisite is met in all the currently supported environments.</p> <p>Note</p> <p>Additionally to reviewing the requirements of the service installation against your supported clusters it is worth doing additional due diligence around the service maturity.</p> <ul> <li>Has the service only recently come into being? (risk of unstable API and increased upgrade burden due to rapid changes having to be propagated through the environments)</li> <li>Is the service relying on pre-stable API groups in kubernetes? While not critical it will mean you need to be extra vigilant on kubernetes control plane upgrade change notes for the inevitable loss of the beta API the service relies on.</li> <li>Does the service have a commerical support offering? Examples include Confluent for Kubernetes and Druid/Imply. These may be requirements for production deployments.</li> </ul> <p>The change request does not necessitate a newer control plane but this may not always be the case - additional planning and testing may be needed if you need to add an external cluster change to internal platform component changes but the same process would be followed with the additional step if pushing a sandbox in the first stage forward on the kubernetes upgrade lifecycle and then propagating those changes up the chain in addition to the internal to the cluster platform deployments.</p> <p>To summarise:</p> <ul> <li>The prerequisites of the change request have been met in the current clusters.</li> <li>The request is a new service rather than a removal or upgrade of an existing service.</li> <li>The request cannot be met using existing components in a different configuration.</li> </ul>"},{"location":"end-to-end/#implementation","title":"Implementation","text":"<p>First task is to imagine the change control flow and quality gates that are between a platform change and production deployment:</p> <ul> <li>Creation of a sandbox to do the initial investigation and configuration.</li> <li>Promotion of changes from a sandbox to the Development environment.</li> <li>Packaging those changes into a versioned artifact for deployment on staging.</li> <li>Promotion of this package into production.</li> </ul> <p></p> <p>Note about Application Sandbox use-cases</p> <p>While this end to end guide is primarily focused on a platform team and their change cycle, it is applicable to application teams with some caveats and simplifications:</p> <ul> <li> <p>You don't need to branch the plaform repository (nor you should have the permissions to do so) in order to provision a sandbox.</p> <p>This is because you have no need to backport changes into the Development cluster platform components, and it allows you to track the moving but stable state of the Development cluster platform components. If as in this guide you need additional platform components they must go through the platform team change cycle and land on development before they can be synced into the application sandboxes. </p> <p>This may seem long winded but it means you have more confidence on migrating your application level changes back to the Development environment as the platform service components you are working against were deployed there first and identical to your sandbox environment.</p> </li> <li> <p>By virtue of this you also inherit the platform state from Development.</p> <p>Because sandboxes are effectively clones of Development that track Developments upstream platform you can keep them running for extended periods of time where it makes sense. Though in addition to this you would need to run the infrastructure as code pipelines that created the sandbox in the first place occasionally to trigger realignment to match the Kubernetes version running in Development.</p> </li> <li> <p>Change promotion should be a case of adding, upgrading or removing HelmRelease objects in environments.</p> </li> </ul> <p>Your applications need to be components, and components get versioned via HelmRelease version values. As such promotion is as simple as promoting those changes up the chain of environments and testing at each waypoint.</p>"},{"location":"end-to-end/#provisioning-a-platform-sandbox","title":"Provisioning a Platform Sandbox","text":"<p>The first action with this diagram the first task is creating a branch in this repository to do work in, branched from <code>main</code>.</p> <p>In this branch you will want to clone the Development environment, as it is set to track against a git repository and branch. However as Development is tracking against <code>main</code> the first change you will need to make is to point the branch reference to track your new branch.</p> <p>Tip</p> <p>It is good practice to use a ticket reference in your branch as a prefix followed by hyphenated summary of the branch function</p> clusters/development/platform.yaml<pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1beta2\nkind: GitRepository\nmetadata:\nname: platform\nnamespace: flux-system\nspec:\nsecretRef:\nname: platform-repository\ninterval: 1m0s\nurl: https://github.com/danielloader/kubernetes-sdlc.git\nref:\nbranch: main\n</code></pre> <p>Next step is provisioning your infrastructure as code template to create a working cluster. You will want to ensure the default context is set correctly, as checked via the <code>kubectl config get-contexts</code> output or explicitly add <code>--context</code> flags for <code>flux</code> and <code>kubectl</code> commands later.</p> <ol> <li> <p>Deploy a new instance of the kubernetes infrastructure of code - incrementing the control plane version or any other baseline modules you have breaking changes in:</p> </li> <li> <p>Kubernetes control plane version being incremented.</p> </li> <li> <p>Core EKS addons versions.</p> </li> <li> <p>Since the above GitRepository object has a <code>.spec.secretRef</code> for a private repository, you will need to provide a secret to connect to the repository with the same name in the <code>flux-system</code> namespace. Details can be found in the FluxCD documentation.</p> </li> <li> <p>Clone the development cluster to a sandbox:</p> <pre><code>rsync -av --exclude='*/gotk-sync.yaml' \"clusters/development/\" \"clusters/sandbox-a\"\n</code></pre> </li> <li> <p>Run FluxCD bootstrap on the new cluster to overwrite the values in the <code>flux-system</code> directory in the cluster directory, this is required to connect the reconciliation loop between source and cluster.</p> </li> </ol> <p>At this point you have a point in time snapshot clone of the Development environment - by virtue of creating a branch in the git repository. Now you're free to make changes to the cluster.</p>"},{"location":"end-to-end/#making-changes-in-the-sandbox","title":"Making Changes in the Sandbox","text":"<p>To install a service like <code>KEDA</code> you will need to create a YAML manifest of the components needed to be deployed using FluxCD:</p> <p>Info</p> <p>This is just an example for this documentation but most services prefer or mandate to run in their own namespace to make RBAC simpler to implement e.g cert-manager, kyverno.</p> platform/services/keda.yaml (example)<pre><code>---\napiVersion: v1\nkind: Namespace\nmetadata:\nname: keda\nlabels:\ntoolkit.fluxcd.io/tenant: sre-team\n---\napiVersion: source.toolkit.fluxcd.io/v1beta2\nkind: HelmRepository\nmetadata:\nname: kedacore\nnamespace: keda\nspec:\ninterval: 30m\nurl: https://kedacore.github.io/charts\n---\napiVersion: helm.toolkit.fluxcd.io/v2beta1\nkind: HelmRelease\nmetadata:\nname: keda\nnamespace: keda\nspec:\nreleaseName: keda\nchart:\nspec:\nchart: keda\nversion: 2.10.2\nsourceRef:\nkind: HelmRepository\nname: kedacore\ninterval: 1h0m0s\ninstall:\nremediation:\nretries: 3\n</code></pre> <p>After committing this file into the relevant branch and directory (platform/services) and pushing, FluxCD will take these three objects and apply them to the cluster and own the reconciliation loop of the objects.</p> <p>Tip</p> <p>The upgrade procedure for most charts would be a version bump in the <code>.spec.chart.spec.version</code> value and any changes mandated in the <code>.spec.values</code> map.</p> <p>At this point it would be prudent to deploy an example to confirm the installation of the controller.</p> <p>Firstly a scaler object, so KEDA knows which deployment to monitor and the appropriate scaling behaviour to apply using <code>kubectl</code>.</p> <p>Note</p> <p>In the teams isolation model, it's not for you as a platform engineer to include a <code>ScaledObject</code> object with this change request, the goal is to evaluate if KEDA is working as advertised in our cluster environment and as such this allows application teams to craft their own for their own application needs.</p> scaler.yaml<pre><code>---\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\nname: cpu-scaledobject\nnamespace: app-a\nspec:\nscaleTargetRef:\nname: podinfo\npollingInterval:  15\ncooldownPeriod:   5\nidleReplicaCount: 1\nminReplicaCount:  1\nmaxReplicaCount:  25\nadvanced:\nhorizontalPodAutoscalerConfig:\nbehavior:  scaleUp:\nstabilizationWindowSeconds: 0\npolicies:\n- type: Pods\nvalue: 10\nperiodSeconds: 15\nselectPolicy: Max\nscaleDown:\nstabilizationWindowSeconds: 3\npolicies:\n- type: Pods\nvalue: 6\nperiodSeconds: 15\nselectPolicy: Max\ntriggers:\n- type: cpu\nmetricType: Utilization # Allowed types are 'Utilization' or 'AverageValue'\nmetadata:\nvalue: \"90\"\n</code></pre> <p>Secondly a job to put some load on the <code>podinfo</code> application that was installed in <code>app-a</code> namespace as inherited as part of the clone from Development. As this is a once and done job, there's no need to put it into the git repository and I would advise just using <code>kubectl</code> to apply and delete the resources as needed. </p> <p>Find a balance between rapidly deploying objects to your sandbox and waiting for a GitOps cycle to complete - by that measure just iterate on a local YAML file and then commit it when you're happy with the state and avoid using <code>kubectl</code> to create objects with options and arguments.</p> load-test.yaml<pre><code>---\napiVersion: batch/v1\nkind: Job\nmetadata:\nname: load-tester\nnamespace: default\nspec:\nttlSecondsAfterFinished: 100\ntemplate:\nspec:\ncontainers:\n- name: wrk\nimage: elswork/wrk\nargs: [\"-t\", \"4\", \"-c\", \"12\", \"-d\", \"180\", \"http://podinfo.app-a:9898\"]\nrestartPolicy: Never\n</code></pre> <p>If all goes well you will get a job running to completion with logs looking similar to the following snippet.</p> <pre><code>Running 3m test @ http://podinfo.app-a:9898\n  4 threads and 12 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    31.64ms   45.23ms   1.29s    83.59%\n    Req/Sec   301.74    191.35     1.32k    65.79%\n  358194 requests in 5.00m, 186.86MB read\nRequests/sec:   1193.52\nTransfer/sec:    637.56KB\nStream closed EOF for default/load-tester-nb4xq (wrk)       </code></pre> <p>In addition to that, during the duration of the load test you should have noticed the <code>podinfo</code> deployment adjusting the replica count and by extension of this, scaling out horizontally.</p> <pre><code>$ kubectl top pods --selector=app.kubernetes.io/name=podinfo -n app-a\nNAME                    CPU(cores)   MEMORY(bytes)   \npodinfo-f7bb67f-gbmjw   3m           13Mi            \npodinfo-f7bb67f-lmdxz   95m          29Mi            \npodinfo-f7bb67f-td86k   3m           13Mi\n</code></pre> <p>So at this point we're happy with the deployment and the dummy scaling workload succeeded some light testing. Next step is applying these changes back to the development environment.</p>"},{"location":"end-to-end/#promoting-changes-from-sandboxes-to-development","title":"Promoting Changes from Sandboxes to Development","text":"<p>Given the creation of this sandbox started with a branch from <code>main</code> it is unsurprising the process to push this change back is in the form of a Merge/Pull request. Raise your request, get some eyes on it, make any changes needed and then merge the resulting outcome.</p> <p>Warning</p> <p>It is essential you do not copy the <code>gotk-sync.yaml</code> directory back to the source or the root level <code>flux-system</code> kustomization will be sourcing files from either the wrong directory and/or wrong branch.</p> <p>So what happens next? Well since Development is tracking the <code>main</code> branch, after a short while FluxCD's source controller will detect a change at the next interval and pull the changes. After the SHA1 hash of the resulting pulled commit changes the downstream objects relying on this source will trigger their own reconciliation loops.</p> <p></p> <p>After a short while if all goes well the Development cluster will have successfully incorporated your change as defined in YAML in git. If it for whatever reason doesn't go that way, you can either fix forwards with additional changes in the sandbox and re-raise the merge or you can revert the commit and back out of the change.</p> <p>Both are viable, but try to fix forwards where you can and consider the revert of a commit when the changes have impacted users of the development cluster as unblocking other teams and users is a top priority when trying to navigate the change promotion process.</p> <p>At this point the change has been promoted to development, any post promotion checking has taken place and the teams who wanted to utilise the service are busy using it in sandboxes of their own automatically as their sandboxes are tracking the main branch of the platform.</p>"},{"location":"end-to-end/#promoting-changes-from-development-to-stagingproduction","title":"Promoting Changes from Development to Staging/Production","text":"<p>At this point we're reasonably happy with the resulting output in development, an application team has been utilising the service for a few sprints but their work is now complete and they themselves need their application to be promoted from Development to Staging on the path of releasing changes to Production.</p> <p></p> <p>Unlike Development, Staging and Production are running tagged bundles of platform components that are published into an OCI Repository (the same repository you're pushing container images in all likelihood).</p> <p>Take the below example from this repository:</p> clusters/staging/platform.yaml<pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1beta2\nkind: OCIRepository\nmetadata:\nname: platform\nnamespace: flux-system\nspec:\nsecretRef:\nname: platform-repository\ninterval: 1m0s\nurl: oci://ghcr.io/danielloader/manifests/platform\nref:\nsemver: 0.0.x ---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\nname: platform-services\nnamespace: flux-system\nspec:\ninterval: 5m\npath: ./platform/services\nprune: true\nsourceRef:\nkind: OCIRepository\nname: platform\n---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\nname: platform-configs\nnamespace: flux-system\nspec:\ninterval: 1m\npath: ./platform/configs\nprune: true\nsourceRef:\nkind: OCIRepository\nname: platform\n---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\nname: platform-service-configs\nnamespace: flux-system\nspec:\ninterval: 1m\npath: ./platform/service-configs\nprune: true\nsourceRef:\nkind: OCIRepository\nname: platform\n</code></pre> <p>FluxCD will be tracking a semver range of patch versions, so if you publish an artifact (which is essentially a .tar.gz bundle of the <code>platform</code> directory of this repository) with a tag with an higher patch version, staging will automatically deploy this.</p> <p>This semi autonomous upgrade behaviour is optional but if you have confidence in your change process and you can rely on patch versioning to be just that, patches, then I'd encourage it.</p> <p>Once this bundle is running on Staging and any testing has been completed to confirm the state of the system is as desired the next and final step is to promote the change to Production.</p> <p>Since Production is sacrosanct I would recommend sticking to a fixed tag deployment, so the <code>.spec.ref.tag</code> field is fixed to exactly the package you want to run. In addition to putting the final gate on deployment to Production it gives visibility to the platform team what is running on production at any given time. While you get the same outcome using SHA1 hashes on a git branch, those change more frequently and aren't as immediately approachable in the case of an outage.</p> <p>Note</p> <p>Final note, you can and should make changes to the platform deployment outside of application team requests, and while it's definitely not always necessary for the platform team to pause promotion of services to production if a team hasn't used them yet - it's definitely preferable. Should the application team decide the request didn't meet their needs it's easier to back a change out of Development, and even Staging than it is once it's in Production.</p> <p>Congratulations you've taken a feature request from inception to Production.</p>"},{"location":"end-to-end/#deleting-a-sandbox","title":"Deleting a Sandbox","text":"<p>After the above it's time to clean up.</p> <p>Info</p> <p>You should feel comfortable to do so as soon as the merge back to <code>main</code>/Development has happened unless you're using it for quick fast follow to fix forward a breaking change in Development.</p> <p>Note</p> <p>As a nice to have it would be worth scripting the clean down procedure, but it is considerably easier than the existing deletion scripts - list all the kustomizations and helm charts with an annotation or label matching a value indicating they mutate state and then subsequently deleting them via kubectl._</p> <p>It makes a lot of sense to start using annotations liberally on this, so you can differentiate between a helm chart of kustomization that provides a custom resource definition and subsequently a controller, and charts which use those. You must remove the custom objects before the controllers, or finalisers cannot be triggered and thus you will end up with dangling resources - some of which will cause your IAC to fail when trying to remove a VPC as those resources are likely still bound inside the VPC (Application load balancers etc). Experiments in this area will come later.</p> <ol> <li>Suspend the root FluxCD entrypoint to prevent self healing of children objects - <code>flux suspend ks flux-system</code></li> <li>Delete the application HelmReleases/Kustomization objects - this is to trigger the finalisers to clear down external resources; EBS volumes, ALB etc.</li> <li>Return the cluster to its freshly bootstrapped state sans any external state. You should be left with a single <code>flux-system</code> kustomization and no HelmRelease objects.</li> <li>Destroy the Kubernetes cluster using the infrastructure as code that deployed it initially.</li> </ol>"},{"location":"concepts/","title":"Concepts","text":"<p>Given the wide scope of this document it's prudent to attempt to get all the readers of this document on to a shared level of understanding around the concepts being explored as to properly enable people to critique and contribute to this document. As such this section can be skipped over if you are comfortable with each heading, though skim reading is advised in case term definitions are misaligned.</p>"},{"location":"concepts/fluxcd/","title":"FluxCD - An Introduction","text":"<p>So with FluxCD selected for the project, here's a high level view of how FluxCD works in the context to making changes to a system:</p> <p></p> <p>The feedback loop described by the diagram above works as follows:</p> <ol> <li>You make a change to a YAML file(s) and commit your changes and push them to a git repository.</li> <li>The FluxCD source controller periodically pulls the repository from git.</li> <li>The FluxCD kustomize and helm controllers run dry applies looking for changes if the source commit hash changes.</li> <li>Any changes detected get reconciled with any sub-object in the cluster that the root controller controls.</li> <li>These reconciled states are now visible to the developer in their local IDE or kubernetes resource viewer (k9s, lens etc).</li> </ol> <p>The rationale for adopting this workflow can be broadly split up into the following goals:</p> <ul> <li>Repeatability - if you want multiple clusters to be in state sync they can all subscribe for changes from the same components, with the same versioning scheme.</li> <li>Promotion of changes - each cluster has a state, enshrined in git; if you want to promote a change it is a case of copying a change from one directory to another and committing the changes.</li> <li>Audit of changes - since you're using merge requests there is an audit log in the git repository of changes made, when and by whom.</li> <li>Disaster recovery - since your state is in code, failing over or rebuilding any environment is easier. 1</li> </ul> <p>The tangible outcome here for teams is having a source of truth to point to and being reasonably confident that is the current state in the cluster.</p> <p>The caveat to this is needing notifications of failure to reconcile state. If you push a broken chart and it fails to apply you need to know that it has failed to apply to know the state in the git repo is not the current state in the cluster.</p> <p>With this brings an improvement to the confidence levels on the cost of a change. If you know the clusters are at a steady known state and you make a change to one cluster, making the same change to other clusters should be less painful.</p> <p>This isn't because the change itself became less risky but instead because the changes became more visible and repeatable - trying to remove manual steps and the human element to changes. Even if you make a bad change the fact it is tracked and visible to all allows easier attribution of cause to problems while simultaneously giving the power to revert to a known working state.</p> <p>Increasing confidence levels and reducing risk in changes reduces the cost of change, and reducing the cost of change is the top priority in the vast majority of architectural designs - if only because business needs are constantly changing and the inability to change to meet them is known as technical debt.</p> <p>Subsequently this allows you to \"move fast and break things\" and embrace an agile culture around your deliverables. Fear of breaking fragile infrastructure has hamstrung software deployment cadence for as long as infrastructure has been needed to enable value to customers.</p>"},{"location":"concepts/fluxcd/#boostrapping","title":"Boostrapping","text":"<p>In FluxCD bootstrapping is the concept of kick starting the reconciliation loop, where in you need to simultaneously put a state in a git repository, as well as a reference to that state in the target kubernetes cluster.</p> <p></p> <ol> <li>Install the FluxCD controller objects into the cluster.</li> <li>Create a <code>GitRepository</code> object that references the flags in the bootstrap command.</li> <li>Add top level root <code>Kustomization</code> object to track itself, the FluxCD components are now tracked in the git repository in the <code>flux-system</code> directory inside a cluster directory.</li> <li>These two objects are then committed and pushed to git and then the same objects are pushed to the kubernetes cluster to start the loop.</li> <li>Finally you can see the reconciliation steps taking place in the cluster with external tooling.</li> </ol> <ol> <li> <p>This process copies the state of a cluster but not the persistent data - underlying persistent data stored in provisioned volumes needs to be treated the same as persistent data on any server - a backup process and restore process needs to be evaluated and tested outside of the infrastructure deployment and cluster deployment lifecycles.\u00a0\u21a9</p> </li> </ol>"},{"location":"concepts/gitops/","title":"GitOps","text":"<p>GitOps in the simplest form is the concept of representing operations state in a git repository with the additional but essential concept that the git repository is the source of truth.</p> <p>The rationale from this is that infrastructure states become well known, sources of truth are centralised and multiple teams can interact with any given infrastructure configuration with some safety net around simultaneous changes using existing development workflows.</p> <p>To achieve this, some of the more classical software development life cycle workflows are adopted but only where it makes sense. Not all software development workflows map well to the declarative world of tangible infrastructure, with long lived branching and gitflow style management of changes being the primary example.</p>"},{"location":"concepts/gitops/#pull-vs-push","title":"Pull vs Push?","text":"<p>In addition to encompassing concept of GitOps you have two competing methodologies for utilising git as the source of truth for infrastructure.</p> <p>A push workflow where in changes are made to a repository and these changes are pushed to resulting clusters to enforce state changes. Any manual changes made in between deployments is effectively overwritten on the next pipeline run, but not before. There is no speculative drift control or warnings things have drifted from the desired state.</p> <p>A pull workflow where in these changes are stored in the repository but the responsibility on reading these changes and reconciling the state of the infrastructure to match the state of the repository is in the hands of the controllers in the infrastructure itself.</p>"},{"location":"concepts/gitops/#push-based-gitops","title":"Push Based GitOps","text":"<p>In a push GitOps the topology changes get promoted to the cluster by way of a push mechanism - primarily in the form of pipelines. Changes in state that the pipelines are configured to listen to subsequently trigger pipelines, this takes the current state in the commit the pipeline operation is referenced to and sets the infrastructure state to match. Common examples:</p> <ul> <li>Terraform plan/apply</li> <li>Helm upgrade/install</li> </ul> <p>This process only happens at the point of a change in the source code, if you do not change the repository for months then the last time the pipelines will run, by default is months ago. If you have infrastructure that is open to change via other methods, directly via a WebUI or CLI tool like AWS, then you can potentially expect state drift.</p> <p>There are ways to mitigate this; running a pipeline on a schedule regularly to reinforce the state that is stored in git as the source of truth, disabling access to mutate infrastructure via other means, culture changes inside the company around the development lifecycle.</p> <p>Due to these pain points and the constant fight against the desire to tinker with a system that is human nature - the pull mechanism was born.</p>"},{"location":"concepts/gitops/#pull-based-gitops","title":"Pull Based GitOps","text":"<p>The pull based GitOps flow builds on the push based and adds in technology that has the job of constantly reconciling state to a known source of truth - if you fiddle with the state of an environment, the controller of the state will revert your changes back to the state stored in the git repository very quickly, fully and with no manual intervention.</p> <p>If you want to change the state of this system your only option is to change the git repository state. 1</p> <p>Which methodology to use and when to swap between the two is up for debate - most companies will start with a push based methodology, simply because it emulates the flow of travel in existing pipelines used for packaging and releasing code.</p> <ol> <li> <p>You can just disable the controller enforcing the state in emergencies if you need to mutate production state, but if you are at that stage you are going to be triggering a post-mortem meeting the next working day around why you had to. Use with care. \u21a9</p> </li> </ol>"},{"location":"concepts/kubernetes/","title":"Kubernetes","text":"<p>This section is not intended to explain what kubernetes is in depth and is more aimed as a high level overview. You should concentrate the value proposition, which can be summarised into three main points:</p> <ul> <li>An abstraction layer between application runtime and operating systems/hardware.</li> <li>A state reconciliation engine for your workloads.</li> <li>A collection of platform components that are designed to work together.</li> </ul> <p>Instead we will focus on the business value the adoption of kubernetes is advertised to bring, and some painful lessons where it adds more friction than it is worth if you do not adopt it as intended, and wholly.</p> <p>Runtime abstraction can be loosely redefined as portability - a concept that drove the initial adoption of C and Java decades ago. It has been a laudable goal since the second computer was turned on - how does one take the software engineering effort and reuse it on new hardware?</p>"},{"location":"concepts/kubernetes/#what-kubernetes-can-be","title":"What Kubernetes Can Be","text":"<p>Kubernetes is just the latest in this nearly century old abstraction on abstraction race to the bottom.</p> <p>In addition to this generalised abstraction it is worthwhile to acknowledge kubernetes itself is not a platform per se, it is a set of APIs or building blocks that you can craft a platform from. Out the box you do not get persistent storage; networking policies or load balancers - all essential components for the vast majority of workloads you would run on a cluster.</p> <p>It is perhaps advisable to think of kubernetes as a bucket of poorly sorted lego - all the bricks have a contract where in they promise to click together with another brick but the blocks themselves do not dictate the final product. Kubernetes is much the same, the components are thoroughly tested to maintain compatibility guarantees but there is no single prescribed way to set up a cluster.</p> <p></p> <p>The overarching selling point to the kubernetes dream is try to limit the cognitive load of the system components:</p> <ul> <li>Developers look after the blue boxes. Isolating the cognitive load to their application responsibilities.</li> <li>Platform team looks after the red area (and if you are fortunate to have it, a different platform team looks after the purple layer).</li> <li>Another team looks after the grey layer; e.g. managed infrastructure like AWS</li> </ul> <p>Kubernetes attempts to abstract away as much as possible about the underlying infrastructure; from which flavour of linux distribution it is running on top of to which CPU microarchitecture the nodes are running.</p> <p>Previously felt acute pain points such as creating an RPM package that ran on a specific flavour of CentOS/RHEL. This in turn would slow down the eagerness of the infrastructure teams to patch operating systems under fear of software failures. This does not go away entirely but the abstraction lessens the coupling between the layers, helps create more aligned infrastructure between stages of deployment (development, staging and production) and increased flexibility to change components deeper down the stack relying on the abstractions to take the brunt of the change for you.</p> <p>To a developer a kubernetes cluster installed on RHEL 7, 8 and 9 as the underlying node operating system should be indistinguishable. 1</p> <p>In addition to this abstraction and isolation principle, kubernetes at its core is a state reconciliation engine. This is extremely important to grok as it might be the most profound and instrumental design choice around the entire ecosystem and it has to be taken into account when designing workloads that are intended to be deployed in a cluster - and failure to account for this design paradigm leads to extremely fragile runtime outcomes.</p> <p></p> <p>While it is not a particularly complex system to grasp, it is one infrastructure engineers have been battling since the first person decided to have multiple replicas of a server running in a group and having the audacity to want them to be somewhat similarly configured.</p> <p>At the core of the kubernetes principle is the idea that you provide a desired state, and the system tries to reconcile that desired state against the current state in the system - correcting for drift as it goes.</p> <p>If you want nine replicas of a container running and some stop working kubernetes will detect the failures and attempt to bring up replicas until the desired count is realigned with the state desired.</p> <p>There are many examples of this reconciliation loop in the kubernetes ecosystem; you could argue all objects given to the control plane represent a fixed state the system needs to align to.</p> <p>This brings us neatly back to GitOps where in a systems state is defined in a git repository - this pattern only works when the control plane you are deploying to can adjust the runtime state of a system and maintain it for you.</p> <p>This repository will explore the FluxCD project for maintaining a defined state of the kubernetes cluster using its various controllers and custom object types.</p> <p>Before jumping onto FluxCD, which makes up the bulk of the rest of this project it is worth discussing alternative technologies and where they sit in the problem space. You can not really safely advocate for a technology unless you know its shortcomings, and a reasonable percentage of its shortcomings will come from alternative technologies doing something better, simpler or cheaper.</p>"},{"location":"concepts/kubernetes/#what-kubernetes-isnt","title":"What Kubernetes Isn't","text":"<p>You would be forgiven for thinking kubernetes is the silver bullet that all organisations can utilise to deliver more value to the customer; reduce costs in infrastructure, improve deployment cadence and solve world hunger.</p> <p>Kubernetes in isolation solves nothing.</p> <p>While I appreciate this is an incendiary judgement; as far as I have seen thus far - kubernetes is a force multiplier, but if you start with a force near zero you are not going to get anything out the back of adopting it - and worse, you will likely incur a lot of downsides.</p> <p>Consider the following questions:</p> <ul> <li> <p>Is your software development lifecycle built around containers (and more recently WASM runtimes)?</p> <p>Failing to meet this requirement means you will not benefit at all by the adoption of a platform built around orchestrating containers. This may sound obvious but having your software development lifecycle built around containers is more than slapping a Dockerfile in the project root and calling it a day. Development ideally happens in containers, testing almost definitely should happen in containers, build pipelines happen using the containers and ultimately deployment has to work in containers - and not just use them but understand their limitations, what they can enable and the value add they bring to the situation.</p> </li> <li> <p>Is your operations team familiar with operating kubernetes clusters?</p> <p>This one is a catch 22 situation. You can run kubernetes in non production workloads to bootstrap the experience needed and the confidence built around the ecosystem to run it in production. This incurs deeper experience than just reading pod logs with <code>kubectl</code> when a pod keeps <code>CrashLoopBackOff</code> looping. Understanding how the various parts of the ecosystem relate to each other, and an understanding of the data flow are important to being able to fix things that are not right. While kubernetes itself is a state reconciliation engine, at the end of the day a platform teams (and or developers on call) job is to the be the state enforcement loop around the existing software defined loop - should all the automation fail, your job is to reset the system into a state where the usual reconciliation can continue back into a steady state.</p> </li> <li> <p>Do you need to change the size of your workload regularly?</p> <p>Kubernetes is reasonably good at adjusting your workloads to the requirements on the system, but only if you put the effort in. There are various middleware solutions that work in conjunction to try to enable this ideal outcome, though essentially they all operate with the same feedback loop:</p> </li> <li> <p>You monitor a metric.</p> </li> <li>The metric changes.</li> <li>The changed metric dictates a change in the replica count in a deployment.</li> <li>Kubernetes cannot schedule the workload due to lack of nodes thus triggering a rescaling of the cluster.</li> <li> <p>You go back to monitoring a metric.</p> <p>There are a lot of moving parts in your average kubernetes cluster and that incurs an operational cost - if you do not need complex operational outcomes, do not use a complex operational cluster system.</p> </li> <li> <p>Do you need to coordinate a workload across multiple geographical regions?</p> <p>It is not impossible to do this with other systems, but the capacity for kubernetes to federate with other clusters to produce a single interaction point across disparate geographical regions can be invaluable.</p> <p>Even without cluster federation being able to have multiple clusters in different regions all using the same git repository as a source of truth makes it easier to maintain a geographically dispersed fleet of workloads.</p> </li> <li> <p>Do you need to produce a product that is at worst \"cloud agnostic\" and at best \"platform agnostic\"?</p> <p>If you are trying to produce a product/service that can deploy to all the various cloud providers it can be easier if you have a common abstraction between those environments. This is doubly true if you are trying to abstract away enough that a developer should not need to know the difference between an on premises deployment utilising VMWare Tanzu or a cloud deployment running on Google Cloud Platform.</p> </li> </ul> <p>This is just the tip of the iceberg when debating the adoption of kubernetes in your organisation or team, there are as many reasons for and against this course of action as there are permutations of kubernetes cluster you can deploy. Though keep in mind none of these are hard and fast rules and sometimes it can make sense when these are not met - primary example would be you have an existing pool of engineers and developers who have prior experience in this space, then it can make sense to adopt it regardless of the purpose.</p>"},{"location":"concepts/kubernetes/#alternatives","title":"Alternatives","text":"<p>Even if you answer all these questions in the direction that would naturally lean towards adopting a kubernetes technology stack in your organisation, it is not the only game in town for this workload management - older and simpler might tick the box for you.</p>"},{"location":"concepts/kubernetes/#redhat-ansible","title":"RedHat Ansible","text":"<p>Ansible has been around for a long time and it seems to have won the adoption race between its contemporary rivals of the era; chef and puppet.</p> <p>The original, and most adopted design pattern for ansible shuns a state reconciliation loop - instead adopting a \"reconcile on push\" model (also referred to as agentless). This is akin to the GitOps push model discussed earlier in this whitepaper. Ansible in this pattern has no capacity to detect drift in a configuration from the source of truth (the git repository) and instead relies on trying to correct the drift correction at the point the pipeline is triggered to deploy an updated ansible playbook.</p> <p>Ansible operates at a lower level of abstraction than kubernetes, and you can deploy a kubernetes cluster itself with ansible - but the lack of constant state reconciliation makes this technology best suited to first run server bootstrapping, infrequently changed deployments and services, and the tooling is focused around configuring operating systems rather than running workloads.</p> <p>It is a common pattern to deploy workloads with ansible, but the runtime of the service itself is managed with Systemd or similar - a fire and forget deployment where native linux tooling is engaged with to try to ensure a service keeps running, and what to do when it fails.</p> <p>Even with the above, ansible has been bent to work in a pull GitOps approach more recently, with ansible-pull - where in ansible runs on a cronjob and pulls the git repository and applies it locally.</p>"},{"location":"concepts/kubernetes/#saltstack","title":"SaltStack","text":"<p>SaltStack essentially tries to solve the same problem that kubernetes does - in respect to reacting to events to change deployments, state drift remediation, and constant feedback loops where the salt minions poll the salt masters for state to resolve while simultaneously reporting their current state.</p> <p>What it does not however attempt to do is abstract out the deployment from the operating system - you are still very much at the whims of the host operating system to make your application run.</p> <p>From that perspective it solves a majority of the problem but is simpler to operate. This leads to an interesting situation to resolve - if you do not need the abstractions, is it possible to get away with a simpler stack?</p> <p>If the answer is yes, you should. Simpler is better, nearly always.</p> <p>You can somewhat operate in the grey area between Salt and Kubernetes by using <code>docker compose</code> or similar technology to run your workloads in containers, but it can end up more complicated than the benefits will offset. Docker compose is not really designed to orchestrate complicated workloads, and can only operate on a host by host basis which generally leads to awkward interactions with cloud managed components such as load balancers.</p> <p>If your workloads are stateless none of this is a problem, however if they are stateful you can end up reimplementing a lot of kubernetes out of the box functionality yourself with Salt and Docker run-times.</p>"},{"location":"concepts/kubernetes/#hashicorp-nomad","title":"Hashicorp Nomad","text":"<p>Hashicorp Nomad exists as a alternative to Kubernetes.</p> <p>It is not exclusively focused on containerised workloads; as it can support virtualised, containerised and stand alone applications - this allows you to skip a requirement from the above considerations block.</p> <p>Nomad strives to offer less, but do it better - and in some workloads this is an ideal compromise, the difficulty comes from the fact it is a niche and not well adopted solution to the problem which can make hiring for it more difficult and time consuming.</p> <p>As of the time of writing it has not adopted the operator pattern that is making kubernetes work for many organisations and this is a considerable feature gap.</p> <p>Though anyone familiar with kubernetes should have enough baseline knowledge to work with Nomad to offset the niche nature of the product.</p>"},{"location":"concepts/kubernetes/#hashicorp-packer","title":"Hashicorp Packer","text":"<p>Hashicorp Packer is an interesting solution to the \"I have something I want to run, how can I package it to run?\" question. Essentially it is a scriptable build pipeline for creating virtual machine images, including cloud deployments like EC2 AMIs. It does not orchestrate, it does not deploy, it does not update your machine nor does it offer any state reconciliation - so why is it on the list?</p> <p>It has been a model for a long time to create fixed function virtual machine images and deploy them to a cluster that runs VMs - and this pattern is called a software appliance. All your state, all your update management, all your telemetry is configured at boot time on first deployment. The operating system itself is configured to try and maintain itself - automatic package upgrades, using docker or systemd on the base operating system to run applications.</p> <p>It is an old model but for some deployments this can make a lot of sense - it is the ultimate abstraction on hardware - you provide a virtualised hardware platform and run the images directly on it. As long as you can provide the CPU core count, memory and storage requirements for the appliance to run you should have a solid production deployment.</p> <p>This model falls apart when you have horizontally scaled workloads that change frequently, or require coordination between dozens of types of applications loosely coupled to each other over the network - it suits monolithic applications.</p>"},{"location":"concepts/kubernetes/#cloud-provider-driven-serverless-computing","title":"Cloud Provider Driven Serverless Computing","text":"<p>As far as you are concerned both operationally and as a developer these machines might as well not exist and you only interact with the workloads via APIs, which is quite compelling to avoid the complexity of kubernetes completely.</p> <p>If you are not tied to needing to requirement to support multiple clouds and or on-premises deployments the cost benefit analysis for serverless workloads is often a case of scale and scale alone.</p> <p>Running serverless functions concurrently 24 hours a day, 7 days a week, will almost always be more expensive than running containers doing the same job. The trade-off is the operational complexity is reduced in exchange for costs.</p> <p>Serverless applications become their own tangled mess of interconnected parts in similar way kubernetes ones do, but there is a wealth of tooling out there to try and tame this problem.</p> <p>Downsides of this methodology include but not limited to:</p> <ul> <li>Costs can spiral quickly making budgeting more complex for finance teams.</li> <li>You are often operationally blind when things do not work as prescribed.</li> <li>Your data flow model is the core of your product and the rest of it is tertiary - you need this mindset and maturity to make a serverless model work or you will end up with a spaghetti-themed deployment.</li> <li>Locally mocking out serverless/managed services can be more complicated than running a slimmed down production-alike kubernetes deployment on a local machine, thereby increasing developer feedback loops on changes.</li> </ul> <p>Conversely upsides include:</p> <ul> <li>Someone else cares if the service is running on a infrastructure level.</li> <li>Someone else cares about provisioning more physical hardware when your workload increases.</li> <li>Billing can be easier to isolate with tagging than in monolithic cloud deployments where mixed workloads run along side each other on shared infrastructure.</li> <li>It will almost always be easier to hire for in the current market trajectory - AWS Lambda will be a similar experience for any developer who has worked with it prior.</li> </ul>"},{"location":"concepts/kubernetes/#summary","title":"Summary","text":"<p>There are a lot of tools written in this space; a lot of different methodologies, and a lot of disagreement on the trade-off between increasing developer productivity and rapid change feedback loops vs operational complexity and deployment pain.</p> <p>There is no right answer and on the off chance you ever think you have one; your business needs will change, the underlying technology will change or your staff skills pool will adjust due to attrition thus leaving your previously correct answer in the wrong camp.</p> <ol> <li> <p>Some cutting edge networking technologies in the kubernetes ecosystem rely on modern kernels to do the eBPF magic they do. Older host OS kernel versions will create a feature gap in this scenario.\u00a0\u21a9</p> </li> </ol>"},{"location":"concepts/loose-coupling/","title":"Loose Coupling","text":"<p>Contrary to the title, this section is actually about the benefits of strong coupling that fails in a way that you can debug and rectify incrementally rather than deleting the entire cluster and starting again.</p> <p>Coupling in the kubernetes sense is a two part subject:</p> <ul> <li>Internal component coupling - Custom Resource Definitions, ConfigMaps and Secrets needing to exist before Objects referencing them.</li> <li>External component coupling - IAM roles needing to exist with the right trust relationship to a OIDC provider to permit IRSA access from a Service Account.</li> </ul> <p>Due to the fact coupling is so contentious when creating a layered system the best option is to have some blind faith the resource you're calling for and relying on exists - and if it doesn't you need to fail safely and report the status of the failure so make debugging easier. All projects should accept transient failures in components and handle them gracefully where possible, especially on kubernetes. If this isn't possible you will need to implement some health-checking logic in an initContainer to prevent the start of your pod.</p>"},{"location":"concepts/loose-coupling/#internal-components","title":"Internal Components","text":"<p>FluxCD offers two ways to handle coupling of components when applied to a cluster:</p> <ul> <li>Direct dependencies that force ordering of reconciliation.</li> <li> <p>Indirect dependencies that fail open and operate safely with a race condition</p> <p>An example would be waiting for the resource to exist before the HelmChart or similar can install, this is commonly found when installing controllers and custom resource objects. The HelmRelease or Kustomization can just keep failing and retrying on the interval period hoping the dependency has been installed concurrently in the background.</p> </li> </ul> <p>There are pros and cons to both methods; direct dependencies are explicit. Take this example:</p> <pre><code>apiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\nname: platform-service-configs\nnamespace: flux-system\nspec:\ndependsOn:\n- name: platform-services\ninterval: 1m\npath: ./platform/service-configs\nprune: true\nsourceRef:\nkind: OCIRepository\nname: platform\n</code></pre> <p>This Kustomization resource will not attempt to reconcile until the Kustomizations that are referenced in the <code>.spec.dependsOn</code> array are successfully showing a ready status, until then it will just be pending.</p> <p>You can also do indirect component coupling as cited above, and this is best suited when handling coupling of application helm charts. If you enforce strict ordering and dependencies in your applications they're probably not as isolated or stand alone - and this almost definitely causes headaches.</p>"},{"location":"concepts/loose-coupling/#external-components","title":"External Components","text":"<p>This is trickier because the cluster has to lazily assume these objects exist outside of the cluster due to the lack of ability to check at install time.</p> <p>IRSA role ARN annotations on Service Accounts would be the most common example, where in you have to assume an IAM role has been provisioned outside the account, with the correct trust relationship and scoped to the correct namespace and service account name.</p> <p>With this example you are forced into extremely tight coupling but indirectly - predictable ARNs for role names for example. You can't know the ARN of the service created for sure, so helm charts will need to guess when creating service account annotations.</p> <p>To aid in this problem you can bootstrap the cluster with a ConfigMap at creation time to include variables that can be used by Kustomization and HelmRelease objects to inject variables into YAML.</p> <p>On EKS the primary beneficial minimum values you would want to include would be:</p> <ul> <li>Cluster AWS Region</li> <li>Cluster Name</li> <li>Cluster AWS Account ID</li> </ul> <p>Using these three things you should be able to script access to other resources in downstream use-cases.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>This repository includes a locally deployable set of instances for exploration and testing.</p> <p>You are required to have the following tools installed before continuing:</p> <ul> <li>Docker</li> <li>yq</li> <li>kind</li> <li>flux</li> </ul>"},{"location":"deployment/create/","title":"Creation of Local Environments","text":"<p>Tip</p> <p>Alternatively if you have taskfile installed - <code>task create</code>.</p> <p>Create the clusters:</p> Kind <pre><code>kind create cluster --config create/$ENV_NAME.yaml\n</code></pre> <p>Bootstrap the clusters with FluxCD whilst being mindful of the owner (group path) and repository name:</p> Gitlab <pre><code>export GITLAB_TOKEN=&lt;your personal access token with api, write_repo, read_registry scoped roles&gt;\nflux bootstrap gitlab --token-auth --owner danielloader --repository fluxcd-demo --path ./clusters/$ENV_NAME --context kind-$ENV_NAME\n</code></pre> <p>Add the Container Registry secret to the <code>flux-system</code> namespace so that the platform components can be pulled:</p> OCIRepository Platform Artifacts (Production/Staging)GitRepository Platform Branch (Deployment/Sandboxes) <pre><code>export GITLAB_USERNAME=&lt;gitlab login email&gt;\nkubectl create secret docker-registry platform-repository --docker-server=registry.gitlab.com --docker-username=\"$GITLAB_USERNAME\" --docker-password=\"$GITLAB_TOKEN\" --namespace flux-system --context kind-$ENV_NAME\n</code></pre> <pre><code>kubectl create secret generic platform-repository -n flux-system --from-literal=username=git --from-literal=password=\"$GITLAB_TOKEN\" --context kind-development\n</code></pre> <p>Now your clusters will be following the state of this repository, as dictated by the <code>clusters/</code> directory, and you can check using kubectl to get the status of the kustomization objects:</p> OCIRepository platform type clusterGitRepository platform type cluster <pre><code>&gt; kubectl get kustomizations -n flux-system --context kind-production\nNAME                       AGE   READY   STATUS\nflux-system                45m   True    Applied revision: main@sha1:32f862f2e10fbaf1f10ff915a6b5b3954ca17037\nplatform-configs           45m   True    Applied revision: 0.0.6@sha256:a02c5784eafe0f93f92378c806ef94bc5dc7b0e653b65039f1c17178e06ab32a\nplatform-service-configs   45m   True    Applied revision: 0.0.6@sha256:a02c5784eafe0f93f92378c806ef94bc5dc7b0e653b65039f1c17178e06ab32a\nplatform-services          45m   True    Applied revision: 0.0.6@sha256:a02c5784eafe0f93f92378c806ef94bc5dc7b0e653b65039f1c17178e06ab32a\n</code></pre> <pre><code>&gt; kubectl get kustomizations -n flux-system --context kind-development\nNAME                       AGE   READY   STATUS\nflux-system                47m   True    Applied revision: main@sha1:32f862f2e10fbaf1f10ff915a6b5b3954ca17037\nplatform-configs           47m   True    Applied revision: main@sha1:32f862f2e10fbaf1f10ff915a6b5b3954ca17037\nplatform-service-configs   47m   True    Applied revision: main@sha1:32f862f2e10fbaf1f10ff915a6b5b3954ca17037\nplatform-services          47m   True    Applied revision: main@sha1:32f862f2e10fbaf1f10ff915a6b5b3954ca17037\n</code></pre>"},{"location":"deployment/destroy/","title":"Destroying Local Environments","text":"<p>Tip</p> <p>Alternatively if you have taskfile installed - <code>task delete</code>.</p> <p>Since these clusters are local, with no external state being deployed you can safely delete the kind clusters without removing anything flux has provisioned:</p> <pre><code>kind delete cluster --name staging\nkind delete cluster --name production\nkind delete cluster --name development\n</code></pre>"},{"location":"implementation/","title":"Implementation","text":"<p>Now the concepts are out of the way the rest of this document will be focused on solving a theoretical problem with a bunch of assumed theoretical functional and non-functional requirements.</p> <p>To help the reader understand what I am trying to build the following statements have been curated.</p> <ol> <li>There is a reason to have multiple clusters running concurrently, for blast radius on change control and isolation of production data.</li> <li>There is a reason to run sandbox clusters that can clone from any cluster; for cost savings and transient use cases.</li> <li>There is a reason to have different application configurations in different environments; permits testing a single component in isolation with mocked services.</li> <li>There is a reason to run different configurations of infrastructure on each cluster; there should be a baseline assumption all clusters will have the same underlying core resources available in every environment for operational overhead reductions but changes will come in time as the underlying components mature.</li> <li>There is a reason to have additional platform and potentially optional components that aren't managed by application teams; Confluent platform, Elastic platform etc.</li> <li>There is a reason to have different clusters tracking changes with different cadences and risk appetite, both in the application and platform infrastructure components.</li> </ol> <p>One important take away is to consider the kubernetes platform a rough equivalent to a linux distribution with its opinionated defaults and services. Much like distributions you will need to maintain a support model around multiple simultaneously deployed versions.</p>"},{"location":"implementation/change-promotion/","title":"Change Promotion","text":"<p>We have discussed how to set out a fixed state but we have not looked at how to make changes to this state safely and promote them between clusters.</p> <p>Developers follow a different change process which will be detailed later, this section is aimed at engineers who maintain the platform components deployed onto every cluster.</p> <p>Nearly all changes to a system are going to start in sandbox environments where the least amount of users are impacted by the changes, so naturally this is our starting point.</p>"},{"location":"implementation/change-promotion/#sandbox-environments","title":"Sandbox Environments","text":"<p>At a high level - Sandboxes encourage or enable the following outcomes:</p> <ul> <li>Cloning the state of an existing cluster at a point in time.</li> <li>Doing provisional upgrades to the control plane and the core platform services.</li> <li>Allow you to run single user performance tests against known configuration type of cluster.</li> <li>Give application teams an opinionated starting point for doing proof of concept work in a disposable yet repeatable manner that maps easily to downstream environments.</li> <li>Encourage a disposable use and tear down workflow for cost savings.</li> </ul> <p>Sandbox environments are commonly thought about but infrequently used, but it is worth explaining why you would go the efforts of engineering to allow these to exist - after all lots of companies do not use them, nor ever find a reason to use them - so why would we?</p> <p>Most change systems will encourage you to make changes at least impactful end of the system as the alternative would be forced to push fresh untested changes into the bottom of the long lived environment stack (in our model, Development).</p> <p>Consider this pyramid where in production has many users (who matter the most as they pay for the service), staging as the next largest user base, then development and finally a sandbox which ideally has one engineer or one team as its user base.</p> <p></p> <p>This methodology where the development environment is a constantly shifting foundation of potentially broken infrastructure is an anti pattern.</p> <p>It prevents development being used for its primary objective - integration testing. Development is likely to be the first changes made by multiple teams in their own isolated sprints and release schedules will interact with each other. Infrastructure should be the stable aspect in this situation, as to allow developers to find bugs and functional issues in their code without needing to rule out issues in the environmental layer underneath. In a sense it is following the scientific principle of minimising variables and promoting repeatable experiments.</p> <p>This does not mean changes will never pass though development as it is the first long lived environment on the promotion to production journey but it is expected a vast majority of the showstopping bugs and feature gaps have been addressed in a sandbox prior to this stage.</p> <p>In addition to facilitating an integration environment, you will likely want to be able to do performance tests.</p> <p>It is important you conduct this test in such a way that yields full confidence of change to a production platform, and thus you can not escape the reality that you need to run performance tests in an environment as identical in topology and compute resource allocation as production - and that is expensive.</p> <p>To alleviate the cost prohibitive situation it makes sense the development environment must be scaled down; be it in absolute compute resources such as smaller CPU/memory/disk allocations, or topological differences such as a single node where you would normally have a three node high availability cluster. Staging and other pre-production environments are in themselves considered a long running environment - ideally production-like in their operation, so it is a common pattern to see staging set up with production scaling.</p> <p>Given the above you still need to perform occasional performance tests - this is just the nature of distributed systems architecture. This is where the concept of a sandbox cluster comes into its own. Utilising the GitOps declarative model you can clone an existing production cluster topology, into a short lived environment where in you can perform a battery of tests against it at the full scale production is running at.</p> <p>The common practice of compromising and utilising staging as a production testing environment has some negative consequences:</p> <ul> <li>Performance testing works best with a rapid change feedback loop; make a change, rerun a test, report these configuration changes yield a percentage change against the baseline.</li> <li>Staging is not the place for making a rapid feedback loop change.</li> <li>Performance testing is often pushing the limits of the system, which incurs breakages and since the staging environment is shared between multiple teams this can become problematic.</li> <li>Testing suites often require a known state to run tests against; pre-populated databases etc. A drift away from this stateful but known state can impact performance outcomes.</li> </ul>"},{"location":"implementation/change-promotion/#platform-sandboxes","title":"Platform Sandboxes","text":"<p>At a high level the operational workflow of a platform team is different to a development team but shares many similarities. Much like a microservice having users and thus needing to maintain a contract between client and server, platform teams have a formalised contract of services they provide that can be utilised by application teams.</p> <p>The differences mostly come from the cadence being set externally; Kubernetes itself has an upstream release cadence of three times a year. Many core infrastructure services deployed in a Kubernetes cluster will be rapidly changing at this point in the Kubernetes maturity cycle. As such the work is more heavily weighted on maintenance than providing additional value. Once there is a stable and relied on baseline platform, application teams will struggle to operate if this moves too quickly - this means changes to deprecate services have to be done conservatively and with a long lead time.</p> <p>Due to this conservative nature of removing services it would be prudent to be conservative on adding services as this incurs additional maintenance burden and adds to the list of services you will need to run through the deprecation cycle at some point in the future.</p> <p></p> <p>In the shared responsibility model talked about prior the platform team gets a hybrid ownership model depending on the scope of their cluster deployment.</p> <p>In a cloud environment the Kubernetes control plane is more than likely to be under the control of the cloud provider by way of a managed service - however that is only a minority of the ownership scope.</p> <p>There is still infrastructure as code modules that have to be maintained to deploy the cloud managed cluster service and all the secondary and tertiary cloud components to make up the platform in its entirety.</p> <p>Note</p> <p>While the application layer is out of scope, if you are making changes that you suspect will affect a development team you should deploy application stacks onto your platform sandbox cluster to helm confirm a healthy state is achieved, and if the state isn't - tickets scheduled with the team warning them of upcoming changes that will incur work to be done.</p> <p>If you take this model with everything resting on the Kubernetes control plane (everything below this is out of scope for the platform team) then the most common breaking change pattern will likely be:</p> <ol> <li>Upstream Kubernetes upgrades are mandated with a breaking change; often promotion of beta APIs to stable or hard removal of alpha and beta API groups.</li> <li>Upstream Helm charts that rely on those core APIs will also change and often take the opportunity to include breaking changes when their underlying APIs change.</li> <li>Applications deployed on the cluster will also need to take into account these changing APIs; e.g. Kyverno policies, Application Load Balancer controller annotations, storage class changes etc.</li> </ol> <p>As you can ascertain the changes at the bottom of the platform are often felt entirely through the stack, as is the nature of foundational changes. Often third parties will attempt to minimise the pain felt by such changes by abstracting the changes in the intermediate layers thereby leaving the application layer none the wiser about the changes below, but this is far from certain.</p> <p>Hopefully this tumultuous but rapid change will settle in due time as maturity takes hold in the design and deployment cycles of the operators that applications leverage, and core Kubernetes API groups reach v1 maturity.</p> <p>Therefore it is notable that the platform team will be likely at the forefront of the breaking changes and change cycles in a clusters lifecycle. You may even get to a point where application stacks on top of the cluster are quite stable, with very infrequent release schedules for their own internally driven roadmap. This in reality does not markedly reduce the amount of releases a team must make, if only because they will have change thrust upon them from below - directly via Kubernetes upgrades and indirectly via shared resources the applications require to run - but these releases will shift to maintenance of a state rather than feature driven deployments.</p> <p>Aside from the minor and patch version bumping of helm charts in the cluster service deployments, the most common and disruptive task in the platform team would be upgrading the Kubernetes control plane itself - at the time of writing the release cadence recently dropped from four releases a year to three, but that still means dealing with this every four months.</p> <p>The Kubernetes control plane has a rolling window of supported API groups which in theory aids the migration and upgrade of clusters. Warnings on deprecation of API groups and object types are made well in advance with some lead times measured in years. This leniency in time pressure around fixing dependencies downstream of the control plane is only useful if you are able to keep on top of the deprecation warnings themselves.</p> <p>There are tools out there to warn you of upcoming hard deprecations, and when you can expect your cluster state to fail if you upgrade the control plane without changes:</p> <ol> <li>pluto - A cli tool to help discover deprecated apiVersions in Kubernetes</li> <li>kubent - Easily check your clusters for use of deprecated APIs</li> </ol> <p>Tip</p> <p>Both tools offer an overlapping venn diagram of features so evaluate both at the time of reading.</p> <p>So now you have a grasp on the scope some up coming changes, what's next?</p> <p>Well you need to create a cluster to try to mitigate the impact of these changes, ideally provisioning the latest version of the control plane as to experiment with the breaking changes ahead of time.</p> <p>Before making changes to a cluster it is worth talking about the differences between an OCIRepository and a GitRepository source; both can be used interchangeably but you could split them into the former providing stability and strong versioning guarantees and the latter allows you the freedom to track changes using any valid git reference.</p> <p>Note</p> <p>Long lived stable clusters should track against OCI artifacts. The exception to the rule would be a canary cluster that is just representing the state of <code>main</code> branches across the stacks to give you an oversight into the health of the system without any users suffering broken environments. Such an environment would represent the minimum scaling of the cluster for cost reasons, and be non-interactive other than to emit errors to your logging platform.</p> <p>Taking the example below of the production cluster and the behaviour the resulting configuration would have in the host cluster:</p> clusters/production/platform.yaml<pre><code>---\napiVersion: source.toolkit.fluxcd.io/v1beta2\nkind: OCIRepository\nmetadata:\nname: platform\nnamespace: flux-system\nspec:\nsecretRef:\nname: platform-repository\ninterval: 1m0s\nurl: oci://ghcr.io/danielloader/manifests/platform\nref:\nsemver: 0.0.x ---\napiVersion: kustomize.toolkit.fluxcd.io/v1\nkind: Kustomization\nmetadata:\nname: platform-services\nnamespace: flux-system\nspec:\ninterval: 5m\npath: ./platform/services\nprune: true\nsourceRef:\nkind: OCIRepository\nname: platform\n</code></pre> <p>In this configuration the configuration is tracking OCI artifacts produced in a pipeline - they're versioned by git tag which triggers their packaging and submission to the OCI repository.</p> <p>Additionally there is semver version tracking, where in you can follow major, minor and patch versions and the latest of which is re-evaluated at the interval period. 1 The constraints on this behaviour are defined in the <code>.spec.ref.semver</code> value and they're evaluated against this rule set.</p> <p>Here are some starting point recommendations for cluster types:</p> <p>Long Lived Types:</p> Environments Notes Production Static artifact reference this cluster is a known state at a glance - a fixed tag. (<code>1.2.3</code>) Staging Somewhat automatic patching this cluster should use a semver range filter and automatically deploy non breaking changes. (<code>1.2.x</code> or <code>1.x.x</code>) Deployment Tracks the <code>main</code> branch of the platform stack, with main being considered a rolling source of truth of a working sack. Will by its nature be usually ahead of tagged releases in staging and production, but not always. It is entirely possible that version <code>1.2.3</code> is deployed simultaneously to production, staging and development if changes haven't been made in a long time and the last commit in the main branch is also <code>1.2.3</code>. Canary Tracks <code>main</code> branch of the platform stack, optionally also <code>main</code> branches of the applications but additionally auto upgrades the control plane. <p>Sandbox Types:</p> Environments Notes Performance Testing You would track the same semver or tag version as the source environment/cluster when cloning an environment. Since you are not intending to merge changes back to the source cluster you do not need to branch from main. As such simply copying a cluster directory and bootstrapping it onto a new cluster is sufficient to get going. Platform Changes The primary purpose of a platform sandbox is to make a change. As such the change needs to follow the trunk based development lifecycle of doing some work in a branch, proposing some changes and opening a pull request to bring those changes back into the development cluster. <p>For a detailed example of utilising platform sandboxes, please refer to the End to End guide.</p>"},{"location":"implementation/change-promotion/#application-sandbox","title":"Application Sandbox","text":"<p>Congratulations, as a development team your only concern is around the application layer - and while that is not devoid of danger, it is however a lot fewer moving parts to worry about and the ones you do have to are somewhat in your gift to control and change.</p> <p>At a high level applications are deployed in the same manner as services are in the platform tier; either as helm charts or kustomized manifests.</p> <p>In contrast to the platform team, having a repository which owns cluster stacks and the infrastructure as code to deploy these stacks, the application teams are encouraged to make repositories per application. Furthermore the definition of an application is fuzzy, especially in the era of microservices which have sometimes tightly coupled functionality mandating cohabitating deployments.</p> <p>While there is not a hard and fast definition in this area a good starting point is treating an application as a standalone deployable stack that delivers a service to a customer or user.</p> <p>Tip</p> <p>It is entirely possible to have nested HelmRelease objects in flux, as the controller listens cluster-wide for objects. This means you can have an \"application\" that is just a collection of HelmRelease and HelmRepository objects that bring in smaller components and cohabitate them into a single namespace and have a parent object to allow full deletion cleanly of a stack.</p> <p>In this repository there is the FluxCD default testing helm chart <code>podinfo</code> as an example of deploying a chart from another repository.</p> <p>Using the same semver range promotion strategy used on the Staging environment you can get FluxCD to auto increment helm releases automatically within the range specified in the HelmRelease objects. Though much like the platform sandboxes for the fastest feedback loops you will find it beneficial to have a GitRepository rather than OCIRepository model for tracking a branch rather than being forced to publish an OCI artifact of a helm chart.</p> <p>Aside from the helm chart itself, an application likely has to ship some custom source code as a container - and this container has to be packaged and published to a container registry so that the Kubernetes cluster can pull it and schedule its execution. If you want to make use of the FluxCD image controllers then you would be best served by having semver compliant tags and avoid the use of a latest tag.</p> <p>Due to this <code>build push &gt; pull &gt; run</code> model the developer feedback loop is quite slow when dealing with containers in the traditional sense.</p> <p>Fortunately there is tooling developed to alleviate some of this slow developer feedback loop pain:</p> <ul> <li>telepresence</li> <li>devspace</li> <li>devpod</li> </ul> <p>Essentially all of them have different approaches to try and expose a remote Kubernetes experience locally so you can make changes quickly, re-run your code and check how it behaves in a remote Kubernetes environment surrounded by the other services you want to interact with.</p> <p>That being said, even if you have the option of using remote development practices to try and force past the pain of having to rebuild a container image on every code change to check if it works - there's no faster feedback loop than local.</p> <p>Given that it is helpful in general to adhere to the design patterns documented by the somewhat famous 12 factor website, which can be described as a manifesto for modern software design practices to aid with development lifecycle and deployment issues.</p> <p>The loose coupling discussed in a different chapter is applicable here - where in you should have some sort of healthcheck capacity in your workloads so that Kubernetes can use readiness and liveness probes to determine the health of the deployment. This manifests in having applications running in the traditional sense but if your lose connectivity to a backend database, while the microservice itself hasn't suffered a runtime fault it should still then provide a failed liveness probe so Kubernetes can create an event and subsequently alert operators of the cluster.</p> <p>On top of that your applications shouldn't be providing their own cluster wide services due to collisions in resources. In the current design of Kubernetes the Custom Resource Definition objects are cluster scoped, so even if you wanted to put an application controller in an application deployment - e.g. Confluent for Kubernetes - you wouldn't gain much agility on decoupled upgrade cycles as any breaking changes to the CRD would affect the operation of all the operators on the cluster regardless. So if you need a controller to deploy some components these controllers should live in the platform stack as optional deployments.</p> <p>Note</p> <p>If the controller doesn't exist, and the CRDs aren't installed, the expected behaviour is your helm chart should fail to install. That is by design and allows you to raise a ticket with the platform team to rectify the missing dependency in the cluster.</p> <p>Hanging off the back of the point around CRDs being cluster wide - you should strive to put all your application objects into a singular namespace to eliminate namespace collisions in clusters being used by multiple people or teams. Namespaces being over used leads to complications on RBAC and network security policies, as well as any needed IRSA IAM roles that need to be provisioned in the application namespace to deploy external cloud resources.</p> <p>Keep it simple.</p> <p>In addition to packaging your applications with Helm, you may find simpler stacks aren't needing such customised deployments and don't necessitate the heavy weight overheard of building and maintaining a helm chart. In those scenarios you should look to just use Kustomize, and specifically the FluxCD kustomization controller to deploy \"bare\" manifests, or manifests with some small patches.</p> <p>Finally, mocks have a mixed reputation but if you can deploy a single application component in isolation with some mocks to test some functionality - if it makes sense to do so, you should.</p> <ol> <li> <p>If you push a <code>0.0.3</code> tagged OCI artifact, and <code>0.0.2</code> is currently running in the cluster, then the rules above would download the <code>0.0.3</code> artifact and trigger reconciliation on the downstream dependencies that use this OCIRepository source.\u00a0\u21a9</p> </li> </ol>"},{"location":"implementation/external-resources/","title":"External Resources","text":"<p>Related to the loose coupling problems talked about some applications inevitably need to store state and often that state is best serviced in a place outside the kubernetes cluster itself. Databases would be top of the list of resources that make sense to store outside of a cluster, utilising cloud provided managed databases wherever possible.</p> <p>It is a common pattern to pre-provision these resources prior to installing helm charts and hoping the connection lines up using things like AWS Secrets Manager to lazily pass connection details down to a consuming application, but this model creates issues with shared resources and cleaning up of resources on uninstallation of an application from the cluster.</p> <p>Given this problem multiple solutions have been build to aid in handling infrastructure from inside your kubernetes manifests natively, so you can deployment alongside your deployments in your helm charts.</p> <p></p> <ul> <li>Crossplane</li> <li>AWS Controllers for Kubernetes</li> <li>Terranetes</li> <li>TF-controller</li> <li>Cloud Config</li> </ul> <p>All of these options follow a similar pattern:</p> <ol> <li>Helm chart includes deployments that need externally provisioned resources.</li> <li>FluxCD installs this HelmRelease that includes a custom resource object for the cloud resource.</li> <li>The cloud resource controller picks up the object, provisions it, and returns outputs like connection strings to a kubernetes secret object.</li> <li>Deployment sits in a waiting to schedule state until the secret exists, then when it does, mounts the secret in a path to use in the application.</li> </ol> <p></p> <p>In addition to the initial provisioning the controller owns the full lifecycle of the resource, and deletion of the Cloud custom object should delete the object via finaliser. This allows a parent HelmRelease object to own both the in cluster compute resources and the external resources and can clean up both.</p> <p>This process is especially fruitful when you have to combine deployment of resources with security groups in AWS, being able to do so in lock step, and clean them up retroactively on deletion to avoid hanging security groups populating the VPC. Then you can use the returned secrets value for the security group Id to populate the annotation in the deployment helm chart so that the pod can start with the correct security group attached to the pod elastic network interface.</p> <p>This model might be the only sane model on how to combine kubernetes resources and managed external resources - it has its own challenges but it couples the internal and external resources over a Secret object and ties their life cycles together to installing and uninstalling an application.</p>"},{"location":"implementation/failure-states/","title":"Failure States","text":"<p>So far we have only covered happy path deployments - changes made, changes successfully applied to the cluster.</p> <p>What happens when the deployments fail? There are many reasons why a deployment may fail but a few examples stand out:</p> <ul> <li>Network connectivity - the target cluster can't connect to the source to get the helm chart or manifests.</li> <li>Permissions connectivity - functionally the same as above but due to credentials failing to authenticate.</li> <li>Configuration mismatch - Unforeseen cluster specific configuration, could happen at the merge to Development stage as other applications and platform teams are promoting their sandbox changes into Development.</li> </ul> <p>The last example requires more analysis.</p> <p>The Development cluster as covered previously is the first time your proposed changes interact with the changes from other teams, this environment is commonly referred to as an integration environment.</p> <p>As such it is natural that this environment has the highest failure rate of change, potentially even higher than sandboxes environments.</p> <p>An increase in moving components nearly always leads to increased failure rate.</p> <p>Note on Shift Left Testing</p> <p>This is by design and a reflection in the system to echo the sentiments in shift-left testing. The cost of change is lower if problems can be found earlier, changes made to mitigate those problems and retrying the change promotion process.</p> <p>Ultimately this is the justification for using sandboxes, so you can get a useful facsimile of a target environment and do your testing scenarios as early as possible in the software development lifecycle.</p> <p>In a sandbox environment it is assumed as an active change environment you are actively engaged with the cluster during change. In a FluxCD driven environment that would be primarily interacting with the Source, Kustomize and Helm controller objects.</p> <p>Much like other components in the kubernetes ecosystem, FluxCD reports a <code>READY</code> state when a component is healthy. Examples of some components reporting healthy status:</p> KustomizationsGitRepositoriesHelmRepositoriesHelmReleases <pre><code>&gt; kubectl get kustomizations --all-namespaces\nNAME                       AGE     READY   STATUS\nflux-system                5m56s   True    Applied revision: main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c\nplatform-configs           5m36s   True    Applied revision: main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c\nplatform-service-configs   5m36s   True    Applied revision: main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c\nplatform-services          5m36s   True    Applied revision: main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c\n</code></pre> <pre><code>&gt; kubectl get gitrepositories --all-namespaces\nNAME          URL                                                   AGE     READY   STATUS\nflux-system   https://github.com/danielloader/kubernetes-sdlc.git   7m42s   True    stored artifact for revision 'main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c'\nplatform      https://github.com/danielloader/kubernetes-sdlc.git   7m22s   True    stored artifact for revision 'main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c'\n</code></pre> <pre><code>&gt; kubectl get helmrepositories --all-namespaces --context kind-development\nNAMESPACE        NAME             URL                                                 AGE     READY   STATUS\nflux-apps        podinfo          https://stefanprodan.github.io/podinfo              9m53s   True    stored artifact: revision 'sha256:09c71269cc5c6286dfd7012738a0eb406efceeac23cd0730bb7bffc814248e38'\nkyverno          kyverno          https://kyverno.github.io/kyverno/                  9m50s   True    stored artifact: revision 'sha256:02e6f2c19d3258697f586de5a937b09128a495ac37b1c684f1d7820ce299b860'\nmetrics-server   metrics-server   https://kubernetes-sigs.github.io/metrics-server/   9m50s   True    stored artifact: revision 'sha256:e9f523294955f69fa52b26770770ce9772d0e6c211d282233c87b02476787e6c'\n</code></pre> <pre><code>&gt; kubectl get helmreleases --all-namespaces\nNAMESPACE        NAME             AGE     READY   STATUS\nflux-apps        podinfo          8m39s   True    Release reconciliation succeeded\nkyverno          kyverno          8m36s   True    Release reconciliation succeeded\nmetrics-server   metrics-server   8m36s   True    Release reconciliation succeeded\n</code></pre> <p>But lets say your access to the git repository fails? What does this look like to you - the engineer using the sandbox.</p> <pre><code>&gt; kubectl get gitrepositories --all-namespaces\nNAMESPACE     NAME          URL                                                   AGE    READY   STATUS\nflux-system   flux-system   https://github.com/danielloader/kubernetes-sdlc.git   134m   True    stored artifact for revision 'main@sha1:06a5a134147d7f9dfb1aeb561e313adf7b78520c'\nflux-system   platform      https://github.com/danielloader/kubernetes-sdlc.git   134m   False   failed to checkout and determine revision: unable to list remote for 'https://github.com/danielloader/kubernetes-sdlc.git': authentication required\n</code></pre> <p>Additional FluxCD documentation on statuses can be found on their website.</p> <p>FluxCD HelmReleases can be configured to automatically remediate certain failure states:</p> <ul> <li>You can retry x times.</li> <li>You can rollback the release to the last known working configuration.</li> </ul> <p>Warning</p> <p>By default if a HelmRelease fails, it just fails and leaves it in a failure state to allow you to investigate those failures. This likely isn't the behaviour you want downstream in the other environments.</p> <p>Lots of situations can yield a false status on the <code>READY</code> value and what happens next would depend on your risk appetite on failure. In a sandbox this would be on you as the engineer making changes to notice when you're working with the cluster but what happens if this happens on a long lived environment where multiple teams are working on it?</p>"},{"location":"implementation/failure-states/#notifications","title":"Notifications","text":"<p>Well FluxCD includes a Notification Controller forward lifecycle events in the FluxCD ecosystem to a third party target.</p> <p>Two primary workflows are important here:</p> <ul> <li>Reporting back to the GitRepository that a certain commit hash is successfully applied.</li> <li>Reporting to a chat/alerting platform that a release has had a successful or failure deployment.</li> </ul> <p>Warning from FluxCD</p> <p>It is important to keep this in mind when building any automation tools that deals with the status, and consider the fact that receiving a successful status once does not mean it will always be successful.</p> <p>Given this, I personally don't see as much value in the commits showing successful states but your mileage may vary. Moreover if you store multiple clusters in the same repository as I have, if you have three or more clusters reconciling to the same commit if one cluster fails and then the others succeed the last recorded state will be a success. </p> <p>Both flows are documented in the above link to the FluxCD documentation so review those and apply them where it makes sense.</p> <p>Note</p> <p>It probably doesn't make sense to include alerts on your sandbox environments, as the signal to noise ratio will be high and people will stop paying attention to chat channels where notifications are being sent to. Additionally it would make some sense to split the chat channels into \"Development\", \"Staging\" and \"Production\" channels so certain people can pay attention to certain environments.</p>"},{"location":"implementation/failure-states/#summary","title":"Summary","text":"<ul> <li>In important environments set strict auto remediation configuration to retry upgrades and/or automatically rolling back.</li> <li>Sandboxes should be perfectly sufficient to be isolated and monitored by the person making the changes.</li> <li>Try not to cause a low signal to noise ratio in any notifications endpoint - noisy Slack channels get ignored.</li> </ul>"},{"location":"implementation/repo-layout/","title":"Git Repository Structure","text":"<p>Abstract</p> <p>There's no single solution for laying out git repositories, they all come with trade-offs. Pick the option that gives the most benefits at the current point in time, but be mindful changing retroactively is extremely painful in a production environment.</p> <p>With that in mind, I'd recommend the model described by FluxCD here. With the platform team owning whole ownership over the clusters and each stream aligned team owning application repositories. It is a compromise balance between access control and separation of concerns.</p> <p>There are no prescribed way to lay out a GitOps workflow for kubernetes; this is partially because every business has their own physical topology and the directory topology should represent this rather than be opposed to it. Additionally the concept of directories in the state has no bearing on the cluster state, any directory layout is purely to aid the human cognitive load - you can (and should not) represent an entire kubernetes cluster in a single monolithic YAML document.</p> <p>An attempt has been made to draw up a topology in this repository that represents a balance between flexibility and declarative rigidity.</p> <p>Don't Repeat Yourself is a contentious subject in any system that represents state declaratively, be it Terraform or Kubernetes manifests. As such there is going to be a mix of duplication and inheritance in this project, representing an attempt to strike a balance. This will only be confirmed retroactively when you try to iron out pain points where in too much inheritance ties your hands on changes having too large of a blast radius, and too much duplication adding to the cognitive load and maintenance costs of running many environments.</p> <p>Having made dozens of passes at this problem before writing up to this point I have settled on this high level cognitive split, a shared responsibility model of sorts.</p> <p></p> <p>The shared responsibility in this scenario can be summarised as follows:</p> <ul> <li>The platform team provide the foundations to build on and as such have a responsibility to be careful with breaking changes, and when they inevitably happen, work in lock step with application teams to test these changes on application stacks.</li> <li>The application teams work inside the platform as defined by the platform team as best as they can, raising feature gaps as and when they occur but under the understanding that not all requests can be adhered to as they may be mutually exclusive requirements with another team or the platform itself.</li> </ul>"}]}